"""
Human File Filter Service

Filters out auto-generated files and keeps only human-written files
suitable for content analysis and AI processing.
"""

import re
from pathlib import Path
from typing import List, Dict, Any, Union


class HumanFileFilter:
    """
    Service for filtering out auto-generated files.
    
    This identifies files that are:
    - Lock files (package-lock.json, yarn.lock, etc.)
    - Minified files (*.min.js, *.min.css)
    - Bundled files (*.bundle.js)
    - Source maps (*.map)
    - Generated files (*.generated.*, *.auto.*)
    - Git internal files (.git/*)
    
    Human-readable files are those written by developers that contain
    meaningful content for analysis, resume generation, and AI processing.
    """
    
    # Lock files that are auto-generated by package managers
    LOCK_FILES = {
        'package-lock.json',
        'yarn.lock',
        'pnpm-lock.yaml',
        'Pipfile.lock',
        'poetry.lock',
        'composer.lock',
        'Gemfile.lock',
        'Cargo.lock',
        'pubspec.lock',
        'packages.lock.json',  # NuGet
        'flake.lock',  # Nix
        'bun.lockb',  # Bun
    }
    
    # Patterns for auto-generated files (compiled as regex)
    EXCLUDED_PATTERNS = [
        r'\.min\.js$',           # Minified JavaScript
        r'\.min\.css$',          # Minified CSS
        r'\.bundle\.js$',        # Bundled JavaScript
        r'\.chunk\.js$',         # Webpack chunks
        r'\.js\.map$',           # JS source maps
        r'\.css\.map$',          # CSS source maps
        r'\.map$',               # Generic source maps
        r'\.generated\.',        # Generated files marker
        r'\.auto\.',             # Auto-generated files marker
        r'\.d\.ts$',             # TypeScript declaration files (often generated)
        r'-lock\.json$',         # Any lock JSON files
        r'\.pyc$',               # Python compiled
        r'\.pyo$',               # Python optimized
        r'\.class$',             # Java compiled
        r'\.o$',                 # Object files
        r'\.so$',                # Shared objects
        r'\.dll$',               # Windows DLL
        r'\.exe$',               # Windows executable
        r'\.wasm$',              # WebAssembly (compiled)
    ]
    
    # Directories that indicate auto-generated content
    EXCLUDED_PATH_PARTS = {
        '.git',
        'node_modules',
        '__pycache__',
        '.next',
        '.nuxt',
        'dist',
        'build',
        'out',
        '.venv',
        'venv',
        'vendor',
        'target',
        '.pytest_cache',
        '.mypy_cache',
        'coverage',
    }
    
    def __init__(self):
        """Compile regex patterns for performance."""
        self._compiled_patterns = [
            re.compile(pattern, re.IGNORECASE) 
            for pattern in self.EXCLUDED_PATTERNS
        ]
    
    def is_human_readable(self, file_path: Union[str, Path]) -> bool:
        """
        Check if a file is human-readable (not auto-generated).
        
        Args:
            file_path: Path to the file (string or Path object)
            
        Returns:
            True if the file is human-readable, False if auto-generated
        """
        path_str = str(file_path)
        filename = Path(path_str).name
        
        # Check if it's a known lock file
        if filename in self.LOCK_FILES:
            return False
        
        # Check if path contains excluded directory
        path_parts = Path(path_str).parts
        for part in path_parts:
            if part in self.EXCLUDED_PATH_PARTS:
                return False
        
        # Check against regex patterns
        for pattern in self._compiled_patterns:
            if pattern.search(path_str):
                return False
        
        return True
    
    def filter_files(self, files: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Filter a list of file dicts to only include human-readable files.
        
        Args:
            files: List of file dictionaries with 'path' key
            
        Returns:
            Filtered list containing only human-readable files
        """
        return [
            f for f in files 
            if self.is_human_readable(f.get("path", ""))
        ]
    
    def get_condensed_files(
        self, 
        project_files: Dict[str, List[Dict[str, Any]]]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        Get a condensed version of project files with only human-readable content.
        
        Args:
            project_files: Dict with keys 'code', 'content', 'image', 'unknown'
            
        Returns:
            Condensed dict with only human-readable files
        """
        return {
            "code": self.filter_files(project_files.get("code", [])),
            "content": self.filter_files(project_files.get("content", [])),
        }
    
    def get_human_readable_contents(
        self,
        directory: Union[str, Path],
        file_extensions: List[str] = None,
        max_chars: int = None
    ) -> str:
        """
        Extract text content from human-readable files in a directory.
        
        Args:
            directory: Path to the directory to scan
            file_extensions: List of file extensions to include (e.g., ['.py', '.js'])
                           If None, includes common code and text files
            max_chars: Maximum total characters to return (for token limits)
                      If None, no limit is applied
            
        Returns:
            Concatenated string of file contents with file path headers
        """
        import os
        
        if file_extensions is None:
            file_extensions = [
                '.py', '.js', '.ts', '.jsx', '.tsx', '.java', '.c', '.cpp', '.h',
                '.cs', '.go', '.rb', '.php', '.swift', '.kt', '.rs', '.scala',
                '.html', '.css', '.scss', '.sass', '.less',
                '.md', '.txt', '.rst', '.json', '.yaml', '.yml', '.xml',
                '.sh', '.bash', '.zsh', '.ps1', '.bat', '.cmd',
                '.sql', '.graphql', '.proto',
            ]
        
        directory = Path(directory)
        contents_parts = []
        total_chars = 0
        
        # Walk the directory
        for root, dirs, files in os.walk(directory):
            # Filter out excluded directories
            dirs[:] = [d for d in dirs if d not in self.EXCLUDED_PATH_PARTS]
            
            for filename in files:
                file_path = Path(root) / filename
                rel_path = file_path.relative_to(directory)
                
                # Check if file extension matches
                if file_extensions:
                    if not any(filename.endswith(ext) for ext in file_extensions):
                        continue
                
                # Check if file is human-readable
                if not self.is_human_readable(str(rel_path)):
                    continue
                
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # Skip empty files
                    if not content.strip():
                        continue
                    
                    # Format with header
                    file_section = f"\n=== {rel_path} ===\n{content}\n"
                    
                    # Check if we would exceed the limit
                    if max_chars is not None:
                        if total_chars + len(file_section) > max_chars:
                            # Add truncation notice and stop
                            remaining = max_chars - total_chars
                            if remaining > 100:
                                contents_parts.append(file_section[:remaining])
                                contents_parts.append("\n... [Content truncated due to size limit] ...")
                            break
                    
                    contents_parts.append(file_section)
                    total_chars += len(file_section)
                    
                except (IOError, OSError):
                    # Skip files that can't be read
                    continue
            
            # Check if we've hit the limit (need to break outer loop too)
            if max_chars is not None and total_chars >= max_chars:
                break
        
        return "".join(contents_parts)
